#import "template.typ" as gost

#set document(title: "КР Орлова, Ершова", author: "Орлова С. Н., Ершова О. А.")

#show: gost.template

#gost.struct-heading("ВВЕДЕНИЕ")

В современной индустрии разработки программного обеспечения ключевую роль играют практики DevOps, направленные на автоматизацию и ускорение жизненного цикла продукта. Одними из фундаментальных инструментов в этой методологии являются системы непрерывной интеграции и непрерывной доставки (Continuous Integration (CI), Continuous Delivery (CD)), которые позволяют автоматически собирать исходное приложение, тестировать его, разворачивать приложение на целевой среде после каждого изменения.

Несмотря на наличие коммерческих и open-source решений, таких как GitLab CI или GitHub Actions, их настройка и использование в небольших проектах или в образовательных целях может быть избыточно сложной. Это создает потребность в разработке легковесных, простых для понимания и развертывания CI/CD-систем, которые реализуют ключевые принципы автоматизации, но не требуют значительных ресурсов для поддержки.

Данная курсовая работа посвящена проектированию и разработке системы "Swompi-Runner". Это CI/CD-сервер, который отслеживает изменения в Git-репозиториях, автоматически запускает пользовательские сценарии в Docker-контейнерах и уведомляет о результатах через Telegram. Система полностью управляется по принципу "Configuration as Code" с помощью YAML-файла, что соответствует современным стандартам в области DevOps.

Цель работы: приобретение профессиональных умений и
навыков, опыта самостоятельной профессиональной деятельности и закрепление
приобретенных компетенций.

Для достижения поставленной цели были определены следующие задачи:
+ Рассмотреть предметную область систем непрерывной интеграции, проанализировать существующие аналоги и на их основе спроектировать архитектуру и модульную структуру собственного приложения.
+ Выбрать и обосновать стек технологий.
+ Разработать структуру базы данных для хранения информации об отслеживаемых репозиториях, истории сборок и их статусах.
+ Реализовать серверную часть приложения, отвечающую за прием веб-хуков от GitHub и запуск исполнителя (Executor).
+ Реализовать модуль-исполнитель Executor, управляющий жизненным циклом Docker-контейнеров, выполнением пользовательских скриптов и сбором артефактов.
+ Реализовать клиентскую часть в виде Telegram-бота и CLI-утилиты для администратора, предоставляющих интерфейс для взаимодействия с системой.
+ Разработать тестовое окружение с использованием Docker Compose для удобного развертывания всех компонентов системы (приложение, база данных, файловое хранилище).
+ Развернуть систему на удаленном VPS-сервере, протестировать ее работу в реальных условиях.

Работа выполнялась командой из двух человек. Распределение задач было произведено следующим образом:
- Орлова С.Н.: Проектирование и реализация ядра системы (модуль-исполнитель Executor), настройка Docker Compose, разработка CLI, взаимодействие с файловым хранилищем.
- Ершова О.А.: структура БД, модели SQLAlchemy, функции для работы с данными, разработка Telegram-бота.

#pagebreak(weak: true)

= Анализ предметной области и существующих решений

Для проектирования системы непрерывной интеграции "Swompi-Runner" в первую очередь был проведен анализ предметной области. Были изучены основные принципы и цели CI/CD, рассмотрены ключевые существующие решения на рынке, а также сформулировано обоснование для разработки собственного программного продукта в рамках курсовой работы.

== Общее описание систем непрерывной интеграции (CI)

Непрерывная интеграция (Continuous Integration, CI) представляет собой практику разработки программного обеспечения, при которой разработчики регулярно вносят изменения в код основного репозитория.

Основной целью практики CI является повышение качества программного продукта и ускорение цикла разработки за счет автоматизации процессов сборки и тестирования. Ключевым событием, запускающим процесс, как правило, являлась отправка (push) нового кода в систему контроля версий.

После получения уведомления о событии CI-сервер выполнял последовательность заранее определенных шагов, именуемую пайплайн (pipeline). Стандартный конвейер включает в себя следующие этапы:
1.  Клонирование исходного кода с системы контроля версий.
2.  Установка необходимых зависимостей, библиотек и инструментов.
3.  Статический анализ кода.
4.  Автоматический запуск тестов.
5.  Сохранение исполняемых файлов, отчетов, Docker-образов.
6.  По результатам выполнения пайплайна разработчикам отправляется отчет о статусе сборки с доступом к логам выполнения.

== Сравнительный анализ аналогов

Для определения ключевых архитектурных подходов и функциональных требований был проведен анализ нескольких популярных CI/CD-решений.

- GitHub Actions. Представляет собой платформу для автоматизации рабочих процессов, тесно интегрированную с репозиториями на GitHub. Конфигурация пайплайнов осуществляется декларативно с помощью YAML-файлов, расположенных в репозитории проекта. Выполнение задач производилось на виртуальных машинах, именуемых "раннерами" (runners), которые предоставляются GitHub или развернуты на собственной инфраструктуре пользователя.

- GitLab CI/CD. Является встроенным инструментом платформы GitLab и обладает схожей с GitHub Actions функциональностью. Конфигурация также описывается в YAML-файле (.gitlab-ci.yml). Система использует концепцию этапов (stages) для группировки задач и поддерживает использование собственных "раннеров" для выполнения сборок в изолированных окружениях.

- Jenkins. Представляет собой автономный open-source сервер автоматизации, который долгое время являлся стандартом в области CI. Его особенностью является высокая расширяемость за счет плагинов. Конфигурация осуществляется через веб-интерфейс и с помощью кода в виде файла Jenkinsfile.

По итогам анализа была составлена сравнительная таблица.

#table(
  columns: 4,
  align: (left, center, center, center),
  [Критерий], [GitHub Actions], [GitLab CI/CD], [Jenkins],

  [Способ конфигурации],
  [YAML-файл в репозитории],
  [YAML-файл в репозитории],
  [Веб-интерфейс, Groovy (Jenkinsfile)],

  [Интеграция],
  [Только с GitHub],
  [Только с GitLab],
  [Автономный, интегрируется со всем],

  [Среда выполнения],
  [Облачные или self-hosted "раннеры"],
  [Облачные или self-hosted "раннеры"],
  [Self-hosted "агенты"],

  [Сложность настройки],
  [Низкая],
  [Низкая],
  [Высокая],
)

Из проведенного анализа был сделан вывод, что современным стандартом для CI-систем является подход "Configuration as Code" (конфигурация как код) с использованием YAML-файлов и выполнение задач в изолированных средах ("раннерах"). Именно эти принципы были взяты за основу при проектировании "Swompi-Runner".

== Обоснование необходимости разработки собственного решения

Несмотря на широкую функциональность проанализированных систем, был выявлен ряд факторов, которые обосновали целесообразность разработки собственного решения в рамках курсовой работы.

Во-первых, промышленные решения, такие как Jenkins, обладали избыточной сложностью для небольших проектов и требовали значительных ресурсов для развертывания и поддержки. Интегрированные платформы, в свою очередь, привязывали разработчика к конкретному хостингу репозиториев (GitHub или GitLab).

Во-вторых, образовательная цель проекта заключалась в изучении механизмов работы CI-систем. Создание собственного сервера позволило на практике исследовать такие процессы, как обработка веб-хуков, управление Docker-контейнерами через API, захват и потоковая передача логов, а также проектирование базы данных и хранилища файлов.

Таким образом, система "Swompi-Runner" должна быть легковесной, простой в развертывании и реализовывать принципы CI/CD систем.

#pagebreak(weak: true)

= Выбор стека технологий

== Язык программирования
В качестве основного языка программирования был выбран Python 3.13 за счет его обширной стандартной библиотеки, огромного количества сторонних пакетов и примеров использования.

== Серверная часть
Для реализации серверной части, ответственной за прием и валидацию веб-хуков от GitHub, был использован фреймворк Flask за его  легковесность и минималистичность.

== База данных и файловое хранилище
Для хранения данных было решено разделить их на два типа: структурированные данные и объектные данные.

База данных выбиралась из собственного опыта, где хорошо себя зарекомендовала PostgreSQL, благодаря своей легкой первоначальной настройке, надежности и производительности.  Для взаимодействия с PostgreSQL из кода была использована ORM SQLAlchemy, позволившая описать структуру БД в виде Python-классов, и драйвер psycopg2-binary для непосредственного подключения.

Для хранения логов и артефактов было выбрано объектное хранилище Garage. Его преимуществом являлась совместимость с S3 API. Это позволило использовать библиотеку boto3 для работы с файлами, обеспечив универсальность кода.

== Изоляция сборок и контейнеризация
Для контейнеризации приложения и запуска пайплайнов в изолированном окружении используется Docker для упрощения развертывания и обеспечения переносимости на различные платформы. Для управления Docker-контейнерами из Python-кода была использована библиотека docker.

== Конфигурация приложения и парсинг
Для управления конфигурацией применена библиотека Pydantic-settings, а для чтения и валидации пользовательских конфигурационных файлов swompi.yml библиотека PyYAML и Schema. 

GitPython был использован для взаимодействия с Git-репозиториями и их клонирования.

== Реализация клиентских интерфейсов
Для взаимодействия с системой были реализованы два клиентских интерфейса:
-  Click: на основе этой библиотеки была создана утилита командной строки, выбрана за счет легкости создания приложения и популярности.
-  тг бот: для реализации бота в Telegram.

== Развертывание и оркестрация
Для развертывания и управления всеми компонентами системы в едином окружении был использован Docker Compose.

#pagebreak(weak: true)

= Проектирование системы "Swompi-Runner"

== Архитектура приложения

=== Обработчик веб-хуков (файл main.py). 

Данный модуль является основной точкой входа в систему. Он был реализован как веб-сервер на базе Flask, прослушивающий POST-запросы на порту 25851. Модуль проверяет, добавлена ли ссылка на репозиторий в базу данных, если да, то извлекает из тела запроса информацию (URL репозитория, хэш коммита, данные об авторе), создает предварительную запись о новой сборке в базе данных со статусом "pending", запускает модуль-исполнитель и отправляет ответ со статусом 200. Если же URL репозитория не добавлен в систему "Swompi-Runner", то запрос отклоняется со статусом 400. Запуск веб-сервера показан на @image2[рисунке].

#figure(image("img/image copy.png"), caption: [Запуск веб-сервера]) <image2>

=== Исполнитель (файл executor.py) 

Реализован класс Executor, который при инициализации запрашивает фабрику создания сессий к базе данных, объект клиента файлового хранилища, объект Config для доступа к переменным окружения. 
Функции класса: 
+ *Основной управляющий метод run_build.* Данный метод является основной точкой входа в класс и управляет всем жизненным циклом выполнения пайплайна. Его работа  обернута в конструкцию try...except...finally для гарантированной обработки ошибок и очистки ресурсов. В рамках его выполнения последовательно вызывались остальные приватные методы.

+ *Подготовка временной директории (\_prepare_workspace).* Для обеспечения полной изоляции каждой сборки была реализована функция, которая с использованием стандартной библиотеки tempfile создавала уникальную временную директорию в системной папке /tmp/. Для удобства отладки каждой директории был присвоен префикс swompi_build_\{build_id\}_.

+ *Клонирование репозитория (\_clone_repo).* На следующем этапе была реализована логика клонирования Git-репозитория. С помощью библиотеки GitPython выполнялась команда clone_from, загружавшая исходный код, и выполнялся переход (checkout) к конкретному коммиту, инициировавшему запуск пайплайна.

+ *Чтение и валидация конфигурационного файла (\_read_and_validate_config).* Сначала вспомогательный метод \_find_config_file находил файл .swompi.yml в корне репозитория. Затем основной метод \_read_and_validate_config валидировал его содержимое. С использованием библиотеки Schema была определена строгая структура ожидаемого файла, а чтение и парсинг YAML-структуры осуществлялись с помощью PyYAML.

+ *Формирование переменных окружения (\_create_enviroment_dict).* Был реализован метод, который формировал словарь переменных окружения для передачи в Docker-контейнер. Этот словарь включал как предопределенные системой переменные (CI_COMMIT_SHA, CI_COMMIT_MESSAGE, CI_COMMIT_AUTHOR, CI_PROJECT_DIR, CI_REPO_URL, CI_BUILD_ID, CI_SERVER_NAME, CI_COMMIT_REF_NAME), так и пользовательские, указанные в файле .swompi.yml.

+ *Создание исполняемого скрипта (\_create_build_script).* Был применен подход с созданием временного shell-скрипта \_run.sh. В этот скрипт последовательно записывались команды из секций before_script и scripts с добавлением директивы set -e, гарантирующей завершение работы при возникновении любой ошибки.

+ *Управление Docker-контейнером (\_run_docker_container).* С помощью библиотеки docker был реализован алгоритм, включавший загрузку Docker-образа, создание и запуск контейнера с монтированной временной директорией и переменными окружения, а также захват логов в реальном времени.

+ *Обработка сбоев (\_mark_build_as_failed).* В случае возникновения исключения или при получении ненулевого кода выхода от контейнера вызывался данный метод. Он обновлял статус текущей сборки в базе данных на failed.

+ *Очистка рабочего пространства (\_cleanup_workspace).* Был реализован метод, который вызывался в блоке finally основного метода. Он полностью и рекурсивно удалял временную директорию со всем ее содержимым.

=== Взаимодействие с базой данных 


=== Файловое хранилище (файл storage.py)

Для инкапсуляции всей логики взаимодействия с S3-совместимым файловым хранилищем Garage был разработан класс FileStorageRepository. Данный компонент отвечал за загрузку и скачивание файлов, а также за первоначальную настройку окружения в хранилище. Его функциональность была разделена на следующие методы:

+ *Инициализация и подключение к S3 (\_create_s_client).* При создании экземпляра класса в конструктор \__init_\_ передавался объект конфигурации приложения. Этот метод  использовал данные для инициализации клиента boto3. Для обеспечения совместимости с self-hosted решением Garage была явно указана версия подписи s3v4 и применен path-style для адресации бакетов.

+ *Автоматическое создание бакета (\_ensure_buckets_exist).* Метод, вызывающийся сразу после инициализации клиента, реализовывал принцип идемпотентности: он отправлял запрос head_bucket для проверки существования необходимого бакета "swompi-runner". В случае, если бакет не был найден, метод автоматически отправлял команду на его создание.

+ *Загрузка логов и артефактов (upload_logs_and_artifacts).* Все файлы сборки, включая лог и артефакты, объединяются в один архив. Для этого создается временная директория, в которую перемещаются файл build.log и все файлы, указанные в секции artifacts. Затем, с использованием библиотеки py7zr, содержимое директории сжимается в единый архив формата .7z, который загружается в S3-хранилище под именем, соответствующим идентификатору сборки. Метод возвращает имя созданного объекта.

+ *Скачивание файлов (download_file_to_path).* Для выгрузки архива метод принимает на вход ключ объекта и локальный путь для сохранения, после чего выполняется скачивание файла.

=== Модуль конфигурации (файл config.py)

Для управления конфигурационными параметрами приложения, такими как учетные данные для доступа к базам данных и внешним API, был применен подход, основанный на отделении конфигурации от кода. 

Вся конфигурация была инкапсулирована в классе AppConfig, унаследованном от класса BaseSettings. Внутри этого класса были объявлены все необходимые для работы системы параметры в виде атрибутов с явным указанием типов данных.

Для параметров POSTGRES_HOSTNAME, S3_ENDPOINT_URL, S3_DEFAULT_REGION были заданы значения по умолчанию. Для переменных S3_ACCESS_KEY, S3_SECRET_KEY и TELEGRAM_BOT_TOKEN, значения по умолчанию отсутствовали. Приложение не может запуститься без предоставления этих параметров, что исключает ошибки во время выполнения, связанные с отсутствием необходимых учетных данных.

Переменные POSTGRES_DB и POSTGRES_USER указываются в файле .env в корневой папке приложения "Swompi-Runner". 

=== Интерфес командной строки (файл cli.py)

Для управления системой был разработан интерфейс командной строки для работы со списком отслеживаемых репозиториев. Для создания CLI была выбрана библиотека Click.

Основная логика была сгруппирована вокруг объекта group, который соответствовал главной исполняемой команде swompi. К этой группе были привязаны три подкоманды, реализующие базовые CRUD-операции.

+ *Команда ls.* Была предназначена для отображения полного списка репозиториев, которые в данный момент отслеживаются системой.

+ *Команда create.* Позволяет добавлять новые репозитории для отслеживания. Была добавлена проверка входных данных, гарантирующая, что предоставленный URL действительно является ссылкой на сервис GitHub.

+ *Команда delete.* Используется для удаления репозитория из списка отслеживаемых. Метод получал URL репозитория в качестве единственного аргумента, после чего вызывал функцию базы данных, которая выполняла поиск и удаление соответствующей записи.

Структура проекта показана на @image1[рисунке]. 

#figure(image("img/image.png"), caption: [Структура проекта]) <image1>

== Структура .swompi.yml файла <structure-swompi-yml>