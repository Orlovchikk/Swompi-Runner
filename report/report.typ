#import "template.typ" as gost

#set document(title: "КР Орлова, Ершова", author: "Орлова С. Н., Ершова О. А.")

#show: gost.template

#gost.struct-heading("ВВЕДЕНИЕ")

В современной индустрии разработки программного обеспечения ключевую роль играют практики DevOps, направленные на автоматизацию и ускорение жизненного цикла продукта. Одними из фундаментальных инструментов в этой методологии являются системы непрерывной интеграции и непрерывной доставки (Continuous Integration (CI), Continuous Delivery (CD)), которые позволяют автоматически собирать исходное приложение, тестировать его, разворачивать приложение на целевой среде после каждого изменения.

Несмотря на наличие коммерческих и open-source решений, таких как GitLab CI или GitHub Actions, их настройка и использование в небольших проектах или в образовательных целях может быть избыточно сложной. Это создает потребность в разработке легковесных, простых для понимания и развертывания CI/CD-систем, которые реализуют ключевые принципы автоматизации, но не требуют значительных ресурсов для поддержки.

Данная курсовая работа посвящена проектированию и разработке системы "Swompi-Runner". Это CI/CD-сервер, который отслеживает изменения в Git-репозиториях, автоматически запускает пользовательские сценарии в Docker-контейнерах и уведомляет о результатах через Telegram. Система полностью управляется по принципу "Configuration as Code" с помощью YAML-файла, что соответствует современным стандартам в области DevOps.

Цель работы: приобретение профессиональных умений и
навыков, опыта самостоятельной профессиональной деятельности и закрепление
приобретенных компетенций.

Для достижения поставленной цели были определены следующие задачи:
+ Рассмотреть предметную область систем непрерывной интеграции, проанализировать существующие аналоги и на их основе спроектировать архитектуру и модульную структуру собственного приложения.
+ Выбрать и обосновать стек технологий.
+ Разработать структуру базы данных для хранения информации об отслеживаемых репозиториях, истории сборок и их статусах.
+ Реализовать серверную часть приложения, отвечающую за прием веб-хуков от GitHub и запуск исполнителя (Executor).
+ Реализовать модуль-исполнитель Executor, управляющий жизненным циклом Docker-контейнеров, выполнением пользовательских скриптов и сбором артефактов.
+ Реализовать клиентскую часть в виде Telegram-бота и CLI-утилиты для администратора, предоставляющих интерфейс для взаимодействия с системой.
+ Разработать тестовое окружение с использованием Docker Compose для удобного развертывания всех компонентов системы (приложение, база данных, файловое хранилище).
+ Развернуть систему на удаленном VPS-сервере, протестировать ее работу в реальных условиях.

Работа выполнялась командой из двух человек. Распределение задач было произведено следующим образом:
- Орлова С.Н.: Проектирование и реализация ядра системы (модуль-исполнитель Executor), настройка Docker Compose, разработка CLI, взаимодействие с файловым хранилищем.
- Ершова О.А.: структура БД, модели SQLAlchemy, функции для работы с данными, разработка Telegram-бота.

#pagebreak(weak: true)

= Анализ предметной области и существующих решений

Для проектирования системы непрерывной интеграции "Swompi-Runner" в первую очередь был проведен анализ предметной области. Были изучены основные принципы и цели CI/CD, рассмотрены ключевые существующие решения на рынке, а также сформулировано обоснование для разработки собственного программного продукта в рамках курсовой работы.

== Общее описание систем непрерывной интеграции (CI)

Непрерывная интеграция (Continuous Integration, CI) представляет собой практику разработки программного обеспечения, при которой разработчики регулярно вносят изменения в код основного репозитория.

Основной целью практики CI является повышение качества программного продукта и ускорение цикла разработки за счет автоматизации процессов сборки и тестирования. Ключевым событием, запускающим процесс, как правило, являлась отправка (push) нового кода в систему контроля версий.

После получения уведомления о событии CI-сервер выполнял последовательность заранее определенных шагов, именуемую пайплайн (pipeline). Стандартный конвейер включает в себя следующие этапы:
1.  Клонирование исходного кода с системы контроля версий.
2.  Установка необходимых зависимостей, библиотек и инструментов.
3.  Статический анализ кода.
4.  Автоматический запуск тестов.
5.  Сохранение исполняемых файлов, отчетов, Docker-образов.
6.  По результатам выполнения пайплайна разработчикам отправляется отчет о статусе сборки с доступом к логам выполнения.

== Сравнительный анализ аналогов

Для определения ключевых архитектурных подходов и функциональных требований был проведен анализ нескольких популярных CI/CD-решений.

- GitHub Actions. Представляет собой платформу для автоматизации рабочих процессов, тесно интегрированную с репозиториями на GitHub. Конфигурация пайплайнов осуществляется декларативно с помощью YAML-файлов, расположенных в репозитории проекта. Выполнение задач производилось на виртуальных машинах, именуемых "раннерами" (runners), которые предоставляются GitHub или развернуты на собственной инфраструктуре пользователя.

- GitLab CI/CD. Является встроенным инструментом платформы GitLab и обладает схожей с GitHub Actions функциональностью. Конфигурация также описывается в YAML-файле (.gitlab-ci.yml). Система использует концепцию этапов (stages) для группировки задач и поддерживает использование собственных "раннеров" для выполнения сборок в изолированных окружениях.

- Jenkins. Представляет собой автономный open-source сервер автоматизации, который долгое время являлся стандартом в области CI. Его особенностью является высокая расширяемость за счет плагинов. Конфигурация осуществляется через веб-интерфейс и с помощью кода в виде файла Jenkinsfile.

По итогам анализа была составлена сравнительная таблица.

#table(
  columns: 4,
  align: (left, center, center, center),
  [Критерий], [GitHub Actions], [GitLab CI/CD], [Jenkins],

  [Способ конфигурации],
  [YAML-файл в репозитории],
  [YAML-файл в репозитории],
  [Веб-интерфейс, Groovy (Jenkinsfile)],

  [Интеграция],
  [Только с GitHub],
  [Только с GitLab],
  [Автономный, интегрируется со всем],

  [Среда выполнения],
  [Облачные или self-hosted "раннеры"],
  [Облачные или self-hosted "раннеры"],
  [Self-hosted "агенты"],

  [Сложность настройки],
  [Низкая],
  [Низкая],
  [Высокая],
)

Из проведенного анализа был сделан вывод, что современным стандартом для CI-систем является подход "Configuration as Code" (конфигурация как код) с использованием YAML-файлов и выполнение задач в изолированных средах ("раннерах"). Именно эти принципы были взяты за основу при проектировании "Swompi-Runner".

== Обоснование необходимости разработки собственного решения

Несмотря на широкую функциональность проанализированных систем, был выявлен ряд факторов, которые обосновали целесообразность разработки собственного решения в рамках курсовой работы.

Во-первых, промышленные решения, такие как Jenkins, обладали избыточной сложностью для небольших проектов и требовали значительных ресурсов для развертывания и поддержки. Интегрированные платформы, в свою очередь, привязывали разработчика к конкретному хостингу репозиториев (GitHub или GitLab).

Во-вторых, образовательная цель проекта заключалась в изучении механизмов работы CI-систем. Создание собственного сервера позволило на практике исследовать такие процессы, как обработка веб-хуков, управление Docker-контейнерами через API, захват и потоковая передача логов, а также проектирование базы данных и хранилища файлов.

Таким образом, система "Swompi-Runner" должна быть легковесной, простой в развертывании и реализовывать принципы CI/CD систем.

#pagebreak(weak: true)

= Выбор стека технологий

== Язык программирования
В качестве основного языка программирования был выбран Python 3.13 за счет его обширной стандартной библиотеки, огромного количества сторонних пакетов и примеров использования.

== Серверная часть
Для реализации серверной части, ответственной за прием и валидацию веб-хуков от GitHub, был использован фреймворк Flask за его  легковесность и минималистичность.

== База данных и файловое хранилище
Для хранения данных было решено разделить их на два типа: структурированные данные и объектные данные.

База данных выбиралась из собственного опыта, где хорошо себя зарекомендовала PostgreSQL, благодаря своей легкой первоначальной настройке, надежности и производительности.  Для взаимодействия с PostgreSQL из кода была использована ORM SQLAlchemy, позволившая описать структуру БД в виде Python-классов, и драйвер psycopg2-binary для непосредственного подключения.

Для хранения логов и артефактов было выбрано объектное хранилище Garage. Его преимуществом являлась совместимость с S3 API. Это позволило использовать библиотеку boto3 для работы с файлами, обеспечив универсальность кода.

== Изоляция сборок и контейнеризация
Для контейнеризации приложения и запуска пайплайнов в изолированном окружении используется Docker для упрощения развертывания и обеспечения переносимости на различные платформы. Для управления Docker-контейнерами из Python-кода была использована библиотека docker.

== Конфигурация приложения и парсинг
Для управления конфигурацией применена библиотека Pydantic-settings, а для чтения и валидации пользовательских конфигурационных файлов swompi.yml библиотека PyYAML и Schema. 

GitPython был использован для взаимодействия с Git-репозиториями и их клонирования.

== Реализация клиентских интерфейсов
Для взаимодействия с системой были реализованы два клиентских интерфейса:
-  Click: на основе этой библиотеки была создана утилита командной строки, выбрана за счет легкости создания приложения и популярности.
-  тг бот: для реализации бота в Telegram.

== Развертывание и оркестрация
Для развертывания и управления всеми компонентами системы в едином окружении был использован Docker Compose.

#pagebreak(weak: true)

= Проектирование системы "Swompi-Runner"

== Архитектура приложения

Структура проекта показана на @image1[рисунке]. 

#figure(image("img/image.png"), caption: [Структура проекта]) <image1>

=== Обработчик веб-хуков (файл main.py). 

Данный модуль является основной точкой входа в систему. Он был реализован как веб-сервер на базе Flask, прослушивающий POST-запросы на порту 25851. Модуль проверяет, добавлен ли url репозитория в базу данных, если да, то извлекает из тела запроса информацию (URL репозитория, хэш коммита, данные об авторе), создает предварительную запись о новой сборке в базе данных со статусом "pending", запускает модуль-исполнитель и отправляет ответ со статусом 200. Если же URL репозитория не добавлен в систему "Swompi-Runner", то запрос отклоняется со статусом 400. Запуск веб-сервера показан на @image2[рисунке].

#figure(image("img/image copy.png"), caption: [Запуск веб-сервера]) <image2>

=== Исполнитель (файл executor.py) 

Реализован класс Executor, который при инициализации запрашивает фабрику создания сессий к базе данных, объект клиента файлового хранилища, объект Config для доступа к переменным окружения. 
Функции класса: 
- run_build: основная функция, которая управляет всем процессом запуска пайплайна, запускает остальные функции.
- \_prepare_workspace: подготавливает временную директорию.
- \_clone_repo: клонирует репозиторий с GitHub с указанной в запросе версией во временную директорию.
- \_find_config_file: ищет файл .swompi.yml в репозитории.
- \_read_and_validate_config: валидирует файл .swompi.yml из репозитория.
- \_create_enviroment_dict: создает словарь с переменными окружения пайплайна и пользовательскими переменными из .swompi.yml файла.
- \_create_build_script: создает сценарий, состоящий из команд .swompi.yml файла, указанных в полях before_script и scripts.
- \_run_docker_container: запускает docker контейнер

Представляет собой ядро CI-системы. Исполнитель п на вход идентификатор сборки и последовательно выполнял весь жизненный цикл пайплайна:
    1.  Клонировал указанную версии репозитория во временную директорию на сервере.
    2.  Читал и валидировал конфигурационный файл .swompi.yml.
    3.  Подготавливал окружение и запускал Docker-контейнер на основе образа, указанного в конфигурации.
    4.  Выполнял пользовательские скрипты внутри контейнера с захватом потоков вывода (stdout/stderr) для формирования лога.
    5.  Собирал и архивировал артефакты.
    6.  Обновлял статус сборки в базе данных и сохранял ссылку на архив.
    7.  Очищал временные файлы и директории.

-   Функции взаимодействия с базой данных и таблицами users, builds, repositories PostgreSQL описаны в файле functions.py. Были 

-   Модуль файлового хранилища (файл storage.py). Был создан класс FileStorageRepository для работы с файловым хранилищем, в котором реализованы функции создания клиента, загрузки и выгрузки файлов.

-   Клиентские интерфейсы (Client Interfaces). Для взаимодействия пользователей и администраторов с системой было реализовано два независимых интерфейса:
    1.  *Telegram-бот:* являлся основным интерфейсом для разработчиков. Он отвечал за отправку уведомлений о статусе сборок, а также предоставлял по командам доступ к истории, логам и артефактам конкретного пайплайна.
    2.  *CLI-администратора:* представлял собой утилиту командной строки (`swompi`), созданную с помощью библиотеки Click. Данный инструмент был предназначен для администратора системы и позволял управлять списком отслеживаемых репозиториев (добавлять, удалять и просматривать их).